{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "owuMk_guREX5",
    "outputId": "ba7cd846-f092-473b-e412-32461a6d779b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "import tensorflow.python.data.kernel_tests.test_base\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "\n",
    "from scripts.load_data import load_train, load_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN bouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_lLaBNewZk0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 31, 1)\n"
     ]
    }
   ],
   "source": [
    "# Het importeren en bewerken van de data \n",
    "train_images, train_labels = load_train()\n",
    "test_images, test_labels = load_test()\n",
    "\n",
    "# Normalizeren van de images\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Reshapen van de images zodat ze de juiste dimensies hebben\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFleZ8yEyFtk"
   },
   "outputs": [],
   "source": [
    "# Onze CNN\n",
    "\n",
    "# Stap 1: bepaal hoeveel filters je wilt, hoe groot je filter size moet zijn (let op je filter size mag niet te groot zijn vergeleken met je images), en wat je pool size is. \n",
    "num_filters = 1\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "# zijn nu random getallen voor de filters\n",
    "\n",
    "# Stap 2: maak het model.\n",
    "#    In de array die je aan sequential meegeeft, zet je alle layers die in het model moeten:\n",
    "#    Conv2D, parameters: num_filters, filter_size, input_shape=(x, y, z)\n",
    "#    MaxPooling2D, parameters: pool_size=pool_size\n",
    "#    Flatten,\n",
    "#    Dense, parameters: aantal outputs, activation='softmax'\n",
    "\n",
    "model = Sequential([])\n",
    "\n",
    "#Conv2d\n",
    "model.add(Conv2D(num_filters, filter_size, input_shape=(28, 31, 1))) #, input_shape=(28, 31, 60000))) # input_shape=(28, 31, 60000) werkt niet\n",
    "#MaxPooling2d\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#Flatten\n",
    "model.add(Flatten())\n",
    "#Dense\n",
    "dense = Dense(2, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "he8Zs-Sd2TID"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n\n    ValueError: Shapes (32, 10) and (32, 182) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [50]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Stap 4: fit het model. \u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#    Data om op te trainen: train_images, to_categorial(train_labels)\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m#    epochs = 3\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#    validation_data = test_images, to_categorial(test_labels)\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\daan\\documents\\vision2022\\visionopdracht5\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1189\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1182\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1183\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1184\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1185\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1186\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1187\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1188\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1189\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1190\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1191\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mc:\\users\\daan\\documents\\vision2022\\visionopdracht5\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mc:\\users\\daan\\documents\\vision2022\\visionopdracht5\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m   1146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m   1148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n\n    ValueError: Shapes (32, 10) and (32, 182) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Stap 3: het compilen van het model. \n",
    "# model.compile parameters: 'adam', loss='categorial_crossentropy', metrics=['accuracy']\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Stap 4: fit het model. \n",
    "#    Data om op te trainen: train_images, to_categorial(train_labels)\n",
    "#    epochs = 3\n",
    "#    validation_data = test_images, to_categorial(test_labels)\n",
    "model.fit(train_images, to_categorical(train_labels), epochs=3, validation_data= (test_images, to_categorical(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 5: evalueer het model\n",
    "test_loss, test_acc = model.evaluate(test_images,  to_categorical(test_labels), verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pS8vERMeHh8j"
   },
   "outputs": [],
   "source": [
    "# Stap 6: extra layer(s). Wat gebeurt er als je een extra Conv Layer toevoegd aan je model? \n",
    "#    Voeg een extra layer(s) toe en train het model opnieuw. \n",
    "# Stap 7: parameters. Wat gebeurt er bijvoorbeeld als je geen softmax gebruikt maar een andere activatie? \n",
    "#    Pas op z'n minst 1 parameter aan en train je model opnieuw. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inladen\n",
    "(train_images10, train_labels10), (test_images10, test_labels10) = cifar10.load_data()\n",
    "\n",
    "plt.imshow(train_images10[4])\n",
    "plt.show()\n",
    "\n",
    "# Normalizeren\n",
    "train_images10, test_images10 = train_images10 / 255.0, test_images10 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 8: bouw je eigen CNN voor de CIFAR-10 dataset. \n",
    "# Tip: gebruik meerdere Conv2D en MaxPooling layers\n",
    "# LET OP: gebruik 'softmax' alleen bij je laatste Dense layer. Gebruik 'relu' voor de andere Conv2D/Dense layers. \n",
    "model_cif = Sequential([])\n",
    "\n",
    "model_cif.compile(\n",
    "    'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cif.fit(\n",
    "  train_images10,\n",
    "  to_categorical(train_labels10),\n",
    "  epochs= #hint: meer dan 3,\n",
    "  validation_data=(test_images10, to_categorical(test_labels10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_cif.evaluate(test_images10,  to_categorical(test_labels10), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronnen\n",
    "* https://victorzhou.com/blog/keras-cnn-tutorial/ Bezocht: 9/3/2020\n",
    "* https://www.tensorflow.org/tutorials/images/cnn Bezocht: 13/3/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}