{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33462,)\n",
      "(33462, 28, 28, 1)\n",
      "(8538,)\n",
      "(8538, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "digits_train = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "\n",
    "#input data for awnsering opdracht\n",
    "digits_test = pd.read_csv(\"data/test.csv\")\n",
    "test_data_in = digits_test.to_numpy()\n",
    "test_data = np.reshape(test_data_in, (test_data_in.shape[0], 28, 28))\n",
    "test_data = np.expand_dims(test_data, axis=3)\n",
    "\n",
    "#split traindata for train and validation data and labels\n",
    "msk = np.random.rand(len(digits_train)) < 0.8\n",
    "train = digits_train[msk]\n",
    "val = digits_train[~msk]\n",
    "\n",
    "#to numpy\n",
    "train_data_in = train.to_numpy()\n",
    "val_data_in = val.to_numpy()\n",
    "\n",
    "\n",
    "# get labels\n",
    "train_labels = train_data_in[:, 0]  # get first colom from the training data\n",
    "val_labels = val_data_in[:, 0]  # get first colom from the training data\n",
    "train_data_without_label = train_data_in[:, 1:]  # remove first colom (labels) from the training data\n",
    "val_data_without_label = val_data_in[:, 1:]  # remove first colom (labels) from the training data\n",
    "\n",
    "\n",
    "# make a 3d array (size, 28, 28)\n",
    "train_data = np.reshape(train_data_without_label, (train_data_without_label.shape[0], 28, 28))\n",
    "val_data = np.reshape(val_data_without_label, (val_data_without_label.shape[0], 28, 28))\n",
    "\n",
    "# make proper dimensions\n",
    "train_data = np.expand_dims(train_data, axis=3)\n",
    "#test_data = np.expand_dims(test_data, axis=3)\n",
    "val_data = np.expand_dims(val_data, axis=3)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(train_data.shape)\n",
    "print(val_labels.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# variables for model\n",
    "num_filters = 2\n",
    "filter_size = (3, 3)\n",
    "pool_size = (3, 3)\n",
    "\n",
    "model = Sequential([])\n",
    "\n",
    "model.add(Conv2D(num_filters, filter_size, padding='same', activation='relu', input_shape=train_data.shape[1:]))\n",
    "model.add(MaxPool2D(pool_size=pool_size))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 4.5804 - accuracy: 0.6187 - val_loss: 0.7235 - val_accuracy: 0.7973\n",
      "Epoch 2/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.4991 - accuracy: 0.8548 - val_loss: 0.3996 - val_accuracy: 0.8842\n",
      "Epoch 3/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.3201 - accuracy: 0.9043 - val_loss: 0.3044 - val_accuracy: 0.9115\n",
      "Epoch 4/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2500 - accuracy: 0.9242 - val_loss: 0.2536 - val_accuracy: 0.9242\n",
      "Epoch 5/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2170 - accuracy: 0.9351 - val_loss: 0.2326 - val_accuracy: 0.9323\n",
      "Epoch 6/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2038 - accuracy: 0.9367 - val_loss: 0.2297 - val_accuracy: 0.9328\n",
      "Epoch 7/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.1963 - accuracy: 0.9389 - val_loss: 0.2180 - val_accuracy: 0.9360\n",
      "Epoch 8/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.1903 - accuracy: 0.9403 - val_loss: 0.2204 - val_accuracy: 0.9365\n",
      "Epoch 9/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.1859 - accuracy: 0.9425 - val_loss: 0.2051 - val_accuracy: 0.9423\n",
      "Epoch 10/10\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.1814 - accuracy: 0.9434 - val_loss: 0.2216 - val_accuracy: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1c30d7f2590>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 - 2s - loss: 0.1752 - accuracy: 0.9446\n",
      "accuracy = 0.9445719122886658\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [24]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m test_loss, test_acc \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(train_data,  train_labels, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(test_acc))\n\u001B[1;32m----> 4\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mimshow(test_data[\u001B[38;5;241m4\u001B[39m])\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(train_data,  train_labels, verbose=2)\n",
    "print(\"accuracy = {}\".format(test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [38]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(test_data[\u001B[38;5;241m4\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\Documents\\vision\\vision2022\\eindopdracht\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1743\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1741\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   1742\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_begin(step)\n\u001B[1;32m-> 1743\u001B[0m   tmp_batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1745\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Documents\\vision\\vision2022\\eindopdracht\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Documents\\vision\\vision2022\\eindopdracht\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m   1146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m   1148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(test_data[4, :, :, 0])\n",
    "plt.show()\n",
    "print(test_data[4].shape)\n",
    "print(model.predict(test_data[4]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}